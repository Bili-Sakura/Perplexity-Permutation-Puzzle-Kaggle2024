{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-30T06:37:59.109914Z","iopub.status.busy":"2024-11-30T06:37:59.109086Z","iopub.status.idle":"2024-11-30T06:38:02.684831Z","shell.execute_reply":"2024-11-30T06:38:02.683925Z","shell.execute_reply.started":"2024-11-30T06:37:59.109835Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch is installed. Version: 2.4.0\n","transformers is installed. Version: 4.45.1\n","pandas is installed. Version: 2.2.3\n","numpy is installed. Version: 1.26.4\n","immutabledict is installed. Version: 4.2.0\n","sentencepiece is installed. Version: 0.2.0\n"]}],"source":["import importlib\n","\n","# List of required packages\n","required_packages = [\n","    \"torch\",\n","    \"transformers\",\n","    \"pandas\",\n","    \"numpy\",\n","    \"immutabledict\", \n","    \"sentencepiece\",\n","]\n","\n","# Check if each package is installed\n","for package in required_packages:\n","    try:\n","        module = importlib.import_module(package)\n","        version = getattr(module, \"__version__\", \"Version not found\")\n","        print(f\"{package} is installed. Version: {version}\")\n","    except ImportError:\n","        print(f\"{package} is NOT installed. Please install it using '!pip install {package}'\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-30T06:38:02.686304Z","iopub.status.busy":"2024-11-30T06:38:02.685954Z","iopub.status.idle":"2024-11-30T06:38:02.724044Z","shell.execute_reply":"2024-11-30T06:38:02.723171Z","shell.execute_reply.started":"2024-11-30T06:38:02.686277Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using 2 GPUs for inference.\n"]}],"source":["import torch\n","\n","# Check available GPUs\n","if torch.cuda.device_count() > 1:\n","    print(f\"Using {torch.cuda.device_count()} GPUs for inference.\")\n","else:\n","    print(\"Only one GPU is available. Using single GPU.\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Load ModelÂ  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-30T06:40:24.586147Z","iopub.status.busy":"2024-11-30T06:40:24.585753Z","iopub.status.idle":"2024-11-30T06:41:54.019269Z","shell.execute_reply":"2024-11-30T06:41:54.016706Z","shell.execute_reply.started":"2024-11-30T06:40:24.586103Z"},"trusted":true},"outputs":[],"source":["from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n","\n","# Define the model directory\n","weights_dir = '/kaggle/input/qwen2.5/transformers/3b-instruct/1'\n","\n","# Load the model and tokenizer from the specified directory\n","tokenizer = AutoTokenizer.from_pretrained(weights_dir)\n","model = AutoModelForCausalLM.from_pretrained(weights_dir,ignore_mismatched_sizes=True,device_map=\"auto\")\n","\n","\n","prompt = \"Give me a short introduction to large language model.\"\n","messages = [\n","    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": prompt}\n","]\n","text = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize=False,\n","    add_generation_prompt=True\n",")\n","model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n","\n","generated_ids = model.generate(\n","    **model_inputs,\n","    max_new_tokens=512\n",")\n","generated_ids = [\n","    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n","]\n","\n","response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":10229277,"sourceId":88046,"sourceType":"competition"},{"isSourceIdPinned":true,"modelId":76277,"modelInstanceId":58215,"sourceId":69765,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelId":164048,"modelInstanceId":141460,"sourceId":166247,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelId":164048,"modelInstanceId":141469,"sourceId":166258,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelId":164048,"modelInstanceId":141580,"sourceId":166386,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelId":76277,"modelInstanceId":72254,"sourceId":104623,"sourceType":"modelInstanceVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
